<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Liang Tong  </title>
  
  <meta name="author" content="Liang Tong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/liangtong.jpeg">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Liang Tong </name>
              </p>
              <p>
                Email: ltong [at] nec-labs [dot] com
              </p>  
              <p>I am a research staff member in the <a href="https://www.nec-labs.com/research-departments/data-science-system-security/data-science-systems-research-home">Data Science & System Security Department</a> at <a href="https://www.nec-labs.com/">NEC Labs America</a>, where I work on machine learning and security.
              </p>  
              <p>
                I received my Ph.D. in CS from <a href="https://wustl.edu/">WashU</a> (under supervision of <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>), my M.S. in CS from <a href="https://www.vanderbilt.edu/">Vanderbilt</a>, and my M.Eng. & B.S. in communication engineering from <a href="https://en.uestc.edu.cn/">UESTC</a>.  
              </p>
              <p>
                <font color="red">Our department is actively hiring research interns (summer 2022) and full-time researchers. Please feel free to check <a href="https://www.nec-labs.com/working-at-nec-labs/search-jobs">here</a> for details and email me if you are interested in working with us at NECLA.</font>
              </p> 
              <p style="text-align:center">
                <a href="docs/liangtong_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=w362AJMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/shinington/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/liangtong.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/liangtong_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                Much of my work lies at the intersection of <em>machine learning</em>, <em>artificial intelligence</em>, and <em>security</em>, with the goal of building <em>trustworthy machine learning systems </em> in various domains such as computer vision, anomaly detection, and malware classification. More specifically, I am interested in using machine learning in security applications and improving robustness of machine learning models themselves. I have also worked on <em>mobile cloud computing</em>, in which I designed edge architectures and transmission schemes for AI applications.

              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- facesec -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/facemask.png' width="100%" height="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Tong_FaceSec_A_Fine-Grained_Robustness_Evaluation_Framework_for_Face_Recognition_Systems_CVPR_2021_paper.pdf">
                <papertitle>FACESEC: A Fine-grained Robustness Evaluation Framework for Face Recognition Systems
                </papertitle>
              </a>
              <br>
              <strong><span style="font-size: 15px">Liang Tong</span></strong>,
              <a href="https://sites.google.com/site/zhengzhangchen/">Zhengzhang Chen</a>,
              <a href="https://nijingchao.github.io/">Jingchao Ni</a>,
              <a href="https://songdj.github.io/">Dongjin Song</a>,
              <a href="https://chengw07.github.io/">Wei Cheng</a>,
              <a href="https://haifengchen.gitlab.io/intro/">Haifeng Chen</a>,
              <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
              <br>
              <em>CVPR</em>, 2021 <br>
              <a
                href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Tong_FaceSec_A_Fine-Grained_CVPR_2021_supplemental.pdf">supplement</a>
              /
              <a href="https://arxiv.org/abs/2104.04107">arXiv</a>
              /
              <a href="https://github.com/shinington/facesec">code</a>
              /
              <a href="https://youtu.be/9EISnIiaEVc">video</a>
              /
              <a href="bibtex/tong2021facesec.bib">bibtex</a>
              <p></p>
              <p>A framework for systematizing adversarial evaluation of face recognition systems. We use this framework to evaluate both closed-set and open-set systems in various adversarial settings.</p>
            </td>
          </tr>

          <!-- DOA -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/doa.png' width="100%" height="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/pdf?id=H1xscnEKDr">
                <papertitle>Defending Against Physically Realizable Attacks on Image Classification
                </papertitle>
              </a>
              <br>
              <a href="https://tongwu2020.github.io/tongwu/">Tong Wu</a>,
              <strong><span style="font-size: 15px">Liang Tong</span></strong>,
              <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
              <br>
              <em>ICLR</em>, 2020 &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font>
              <br>
              <a
                href="https://arxiv.org/abs/1909.09552">arXiv</a>
              /
              <a href="https://github.com/tongwu2020/phattacks">code</a>
              /
              <a href="https://iclr.cc/virtual_2020/poster_H1xscnEKDr.html">video</a>
              /
              <a href="bibtex/wu2020defending.bib">bibtex</a>
              <p></p>
              <p></p>We find that adversarial training with PGD attacks and randomized smoothing are not effective in defending against physically realizable attacks. Our design of a new threat model lets adversarial training obtain generalizable robustness to these attacks in different domains. 
            </td>
          </tr>

          <!-- Alert Prioritization -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/alert_prioritization.png' width="100%" height="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5442">
                <papertitle>Finding Needles in a Moving Haystack: Prioritizing Alerts with Adversarial Reinforcement Learning
                </papertitle>
              </a>
              <br>
              <strong><span style="font-size: 15px">Liang Tong</span></strong>,
              <a href="https://aronlaszka.com/">Aron Laszka</a>,
              <a href="https://cybersecurity.seas.wustl.edu/ning/index.html">Ning Zhang</a>,
              <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
              <br>
              <em>AAAI</em>, 2020 
              <br>
              <a
                href="https://arxiv.org/abs/1906.08805">arXiv (long version)</a>
              /
              <a href="https://github.com/shinington/AlertPrioritization">code</a>
              /
              <a href="bibtex/tong2020finding.bib">bibtex</a>
              <p></p>
              <p></p>One of the major challenges in using detection systems in practice is dealing with an overwhelming number of alerts triggered by normal behavior (the so-called false positives), obscuring alerts resulting from actual malicious activity. We introduce a novel approach for computing a policy for prioritizing alerts using adversarial reinforcement learning.
            </td>
          </tr>

          <!-- Conserved Features -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/conserved_feature.png' width="100%" height="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.usenix.org/system/files/sec19-tong.pdf">
                <papertitle>Improving Robustness of ML Classifiers against Realizable Evasion Attacks Using Conserved Features
                </papertitle>
              </a>
              <br>
              <strong><span style="font-size: 15px">Liang Tong</span></strong>,
              <a href="https://aisecure.github.io/">Bo Li</a>,
              <a href="https://www.ariel.ac.il/wp/chen-hajaj/">Chen Hajaj</a>,
              <a href="https://xiaocw11.github.io/">Chaowei Xiao</a>,
              <a href="https://cybersecurity.seas.wustl.edu/ning/index.html">Ning Zhang</a>,
              <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
              <br>
              <em>USENIX Security</em>, 2019 
              <br>
              <a
                href="https://arxiv.org/abs/1708.08327">arXiv</a>
              /
              <a href="https://github.com/shinington/Robust-PDF-Classifier-with-Conserved-Features">code</a>
              /
              <a href="https://www.youtube.com/watch?v=eOj7EipZmq0">video</a>
              /
              <a href="bibtex/tong2019improving.bib">bibtex</a>
              <p></p>
              <p></p>We find that 1) in the context of ML-based PDF malware detection, feature-space attack models are not good proxies to real attacks in problem space, and 2) <em>conserved features</em> are the key to bridge the gap, as well as to provide generalizable defense.
            </td>
          </tr>

          <!-- Multiple Learners -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/multiple_learner.png' width="100%" height="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://proceedings.mlr.press/v80/tong18a/tong18a.pdf">
                <papertitle>Adversarial Regression with Multiple Learners
                </papertitle>
              </a>
              <br>
              <strong><span style="font-size: 15px">Liang Tong</span></strong>*,
              <a href="http://sixie-yu.org/">Sixie Yu*</a>,
              <a href="https://salfeld.github.io/">Scott Alfeld</a>,
              <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
              <br>
              <em>ICML</em>, 2018 
              <br>
              <a href="http://proceedings.mlr.press/v80/tong18a/tong18a-supp.pdf">supplement</a>
              /
              <a href="https://arxiv.org/abs/1806.02256">arXiv</a>
              /
              <a href="https://github.com/marsplus/Adversarial-Regression-with-Multiple-Learners">code</a>
              /
              <a href="https://vimeo.com/287807252">video</a>
              /
              <a href="bibtex/tong2018adversarial.bib">bibtex</a>
              <p></p>
              <p></p>In many situations, an adversary’s decision is aimed at a collection of ML learners rather than specifically targeted at each independently. We study the problem of adversarial linear regression with multiple learners and propose a game-theoretic approach for defense by modeling the interactions between the learners and the adversary.
            </td>
          </tr>

          <!-- Traffic Scheduling -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/traffic_scheduling.png' width="100%" height="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="papers/tong2016application.pdf">
                <papertitle>Application-Aware Traffic Scheduling for Workload Offloading in Mobile Clouds
                </papertitle>
              </a>
              <br>
              <strong><span style="font-size: 15px">Liang Tong</span></strong>*,
              <a href="http://web.eecs.utk.edu/~weigao/">Wei Gao</a>
              <br>
              <em>INFOCOM</em>, 2016 &nbsp <font color="red"><strong>(Best Presentation in Session)</strong></font>
              <br>
              <a href="slides/tong2016application_slides.pdf">slides</a>
              /
              <a href="bibtex/tong2016application.bib">bibtex</a>
              <p></p>
              <p></p>We adaptively balance the tradeoff between energy efficiency and responsiveness of mobile applications by developing application-aware wireless transmission scheduling algorithms for mobile cloud computing.
            </td>
          </tr>

          <!-- Hierarchical Edge Cloud -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/hierarchical.png' width="100%" height="100%">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="papers/tong2016a.pdf">
                <papertitle>A Hierarchical Edge Cloud Architecture for Mobile Computing
                </papertitle>
              </a>
              <br>
              <strong><span style="font-size: 15px">Liang Tong</span></strong>*,
              Yong Li,
              <a href="http://web.eecs.utk.edu/~weigao/">Wei Gao</a>
              <br>
              <em>INFOCOM</em>, 2016 
              <br>
              <a href="slides/tong2016a_slides.pdf">slides</a>
              /
              <a href="bibtex/tong2016a.bib">bibtex</a>
              <p></p>
              <p></p>We propose to deploy cloud servers at the network edge and design the edge cloud as a tree hierarchy of geo-distributed servers, so as to efficiently utilize the cloud resources to serve the peak loads from mobile users.
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Patents</heading>
              <ul>
                <li>
                <a href="https://patentimages.storage.googleapis.com/51/fb/35/9e4d547cc6c3ca/US20210300433A1.pdf">
                <papertitle>Systems and Methods for Defending against Physical Attacks on Image Classification
                </papertitle>
              </a>
              <br>
              <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>,
              <a href="https://tongwu2020.github.io/tongwu/">Tong Wu</a>,
              <strong><span style="font-size: 15px">Liang Tong</span></strong>
              <br>
              US Patent App. 17/214,071, 2021
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Interns</heading>
              <ul>
                <li>Nauman Ahad (Georgia Tech): summer 2021</li>
              </ul>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
              <ul>
                <li>CSE 411A AI and Society (Fall 2019), Washington University in St. Louis</li>
                <li>CSE 544T Special Topics in Computer Science Theory - Adversarial AI (Spring 2019), Washington University in St. Louis </li>
                <li>CS 102 Introduction to Computer Science (Spring 2015), University of Tennessee</li>
                <li>CS 160 Computer Organization (Fall 2014), University of Tennessee</li>
                <li>Access Network Technology (Spring 2011), University of Electronic Science and Technology of China</li>
              </ul>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="2">
                    Website credit: <a href="https://jonbarron.info/">Jon Barron</a>
                  </font>
                </p>
              </td>
            </tr>
    </tbody>
  </table>

</body>

</html>
