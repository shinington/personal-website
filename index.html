<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Liang Tong</title>
  
  <meta name="author" content="Liang Tong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table 
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <table 
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Liang Tong </name>
                  </p>
                  <p>
                    Email: liangtong39 [at] gmail [dot] com
                  </p>  
                  <p>I am a senior security machine learning researcher at <a href="https://stellarcyber.ai/">stellarcyber.ai</a> working on AI for threat detection and response. Before this, I was a researcher in the <a href="https://www.nec-labs.com/research/data-science-system-security/home/">Data Science & System Security Department</a> at <a href="https://www.nec-labs.com/">NEC Labs America</a> where I worked on trustworthy machine learning and time series analysis.
                  </p>  
                  <p>I received my Ph.D. in CS from <a href="https://wustl.edu/">WashU</a> with the Turner Dissertation Award (under supervision of <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>), my M.S. in CS from <a href="https://www.vanderbilt.edu/">Vanderbilt</a>, and my M.Eng. & B.S. in communication engineering from <a href="https://en.uestc.edu.cn/">UESTC</a>.  
                  </p>
                  <p><font color="red">We are actively hiring researchers, research engineers, and interns. Details can be found <a href="https://stellarcyber.ai/company/careers/">here</a>.</font>
                  </p> 
                  <p style="text-align:center">
                    <!--<a href="docs/liangtong_cv.pdf">CV</a> &nbsp/&nbsp-->
                    <a href="https://scholar.google.com/citations?user=w362AJMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://github.com/shinington/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/liangtong.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/liangtong_circle.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table 
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    I am passionate about 1) AI for security applications and 2) understanding when/why AI fails and how to prevent failures (trustworthy AI).
                  </p>
                  <p>  
                    Much of my work lies at the intersection of <em>machine learning</em>, <em>artificial intelligence</em>, and <em> computer security</em>. More specifically, I am interested in using machine learning to improve system and network security, and improving security of the machine learning models themselves in adversarial settings. I have also worked on <em>mobile cloud computing</em>, in which I designed architectures and transmission schemes for offloading mobile AI applications to edge cloud.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table 
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- AIOps -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/aiops.png' width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2302.01987.pdf">
                    <papertitle>Hierarchical Graph Neural Networks for Causal Discovery and Root Cause Localization
                    </papertitle>
                  </a>
                  <br>
                  <a href="https://wangdongjie100.github.io/">Dongjie Wang</a>,
                  <a href="https://sites.google.com/site/zhengzhangchen/">Zhengzhang Chen</a>,
                  <a href="https://nijingchao.github.io/">Jingchao Ni</a>,
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,
                  <a href="https://www.linkedin.com/in/zheng-wang-a18396238/">Zheng Wang</a>,
                  <a href="https://yanjiefu.com/">Yanjie Fu</a>,
                  <a href="https://haifengchen.gitlab.io/intro/">Haifeng Chen</a>,
                  <br>
                  <em>KDD</em>, 2023 <br>
                  <a href="bibtex/wang2023hierarchical">bibtex</a>
                  <p></p>
                  <p>A GNN framework for causal discovery and root cause localization.</p>
                </td>
              </tr>  
              
              <!-- FedMN -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/personalized_fl.png' width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2210.14830.pdf">
                    <papertitle>Personalized Federated Learning via Heterogeneous Modular Networks
                    </papertitle>
                  </a>
                  <br>
                  <a href="https://ist.psu.edu/directory/tkw5356">Tianchun Wang</a>,
                  <a href="https://chengw07.github.io/">Wei Cheng</a>,
                  <a href="https://users.cs.fiu.edu/~dluo/">Dongsheng Luo</a>,
                  <a href="https://www.linkedin.com/in/yuwenchao/">Wenchao Yu</a>,
                  <a href="https://nijingchao.github.io/">Jingchao Ni</a>,
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,                  
                  <a href="https://haifengchen.gitlab.io/intro/">Haifeng Chen</a>,
                  <a href="https://faculty.ist.psu.edu/xzz89/">Xiang Zhang</a>
                  <br>
                  <em>ICDM</em>, 2022 <br>
                  <a href="bibtex/tong2021facesec.bib">bibtex</a>
                  <p></p>
                  <p>A personalized federated learning framework for heterogeneous clients.</p>
                </td>
              </tr>    
              
              <!-- dissertation -->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/dissertation.png' width="160" height="100">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="papers/tong2021towards.pdf">
                    <papertitle>Towards Deploying Robust Machine Learning Systems
                    </papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>
                  <br>
                  <em>Doctoral dissertation, Washington University in St. Louis</em>, 2021 &nbsp <font color="red"><strong>(Turner Dissertation Award, the best Ph.D. thesis of WashU CS)</strong></font>
                  <br>
                  <a href="bibtex/tong2021towards.bib">bibtex</a>
                  <p></p>
                  <p>A systematic study on adversarial evaluation, defense, and deployment of ML systems.</p>
                </td>
              </tr>

              <!-- facesec -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/facemask_attack.png' width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Tong_FaceSec_A_Fine-Grained_Robustness_Evaluation_Framework_for_Face_Recognition_Systems_CVPR_2021_paper.pdf">
                    <papertitle>FACESEC: A Fine-grained Robustness Evaluation Framework for Face Recognition Systems
                    </papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,
                  <a href="https://sites.google.com/site/zhengzhangchen/">Zhengzhang Chen</a>,
                  <a href="https://nijingchao.github.io/">Jingchao Ni</a>,
                  <a href="https://songdj.github.io/">Dongjin Song</a>,
                  <a href="https://chengw07.github.io/">Wei Cheng</a>,
                  <a href="https://haifengchen.gitlab.io/intro/">Haifeng Chen</a>,
                  <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
                  <br>
                  <em>CVPR</em>, 2021 <br>
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Tong_FaceSec_A_Fine-Grained_CVPR_2021_supplemental.pdf">supplement</a>
                  /
                  <a href="https://arxiv.org/abs/2104.04107">arXiv</a>
                  /
                  <a href="https://github.com/shinington/facesec">code</a>
                  /
                  <a href="https://youtu.be/9EISnIiaEVc">video</a>
                  /
                  <a href="bibtex/tong2021facesec.bib">bibtex</a>
                  <p></p>
                  <p>A framework for systematizing adversarial evaluation of face recognition systems.</p>
                </td>
              </tr>

              <!-- DOA -->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/doa.png' width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/pdf?id=H1xscnEKDr">
                    <papertitle>Defending Against Physically Realizable Attacks on Image Classification
                    </papertitle>
                  </a>
                  <br>
                  <a href="https://tongwu2020.github.io/tongwu/">Tong Wu</a>,
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,
                  <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
                  <br>
                  <em>ICLR</em>, 2020 &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font>
                  <br>
                  <a
                    href="https://arxiv.org/abs/1909.09552">arXiv</a>
                  /
                  <a href="https://github.com/tongwu2020/phattacks">code</a>
                  /
                  <a href="https://iclr.cc/virtual_2020/poster_H1xscnEKDr.html">video</a>
                  /
                  <a href="bibtex/wu2020defending.bib">bibtex</a>
                  <p></p>
                  <!--Adversarial training with PGD attacks is not effective in defending against physically realizable attacks. Our design of a new threat model addresses this issue.-->
                  <p>Is robust ML really robust in the face of physically realizable attacks on image classifications? This paper provides a rethinking of adversarial robustness.</p> 
                </td>
              </tr>

              <!-- Alert Prioritization -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/arl_expr.png' width="160" height="140">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5442">
                    <papertitle>Finding Needles in a Moving Haystack: Prioritizing Alerts with Adversarial Reinforcement Learning
                    </papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,
                  <a href="https://aronlaszka.com/">Aron Laszka</a>,
                  <a href="https://cybersecurity.seas.wustl.edu/ning/index.html">Ning Zhang</a>,
                  <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
                  <br>
                  <em>AAAI</em>, 2020 
                  <br>
                  <a
                    href="https://arxiv.org/abs/1906.08805">arXiv (long version)</a>
                  /
                  <a href="https://github.com/shinington/AlertPrioritization">code</a>
                  /
                  <a href="bibtex/tong2020finding.bib">bibtex</a>
                  <p></p>
                  <p>A robust ML model is not the end of the story. We need to deal with the false-positive alerts raised by ML models.</p>
                </td>
              </tr>

              <!-- Conserved Features -->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/conserved_feature.png' width="160" height="140">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.usenix.org/system/files/sec19-tong.pdf">
                    <papertitle>Improving Robustness of ML Classifiers against Realizable Evasion Attacks Using Conserved Features
                    </papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,
                  <a href="https://aisecure.github.io/">Bo Li</a>,
                  <a href="https://www.ariel.ac.il/wp/chen-hajaj/">Chen Hajaj</a>,
                  <a href="https://xiaocw11.github.io/">Chaowei Xiao</a>,
                  <a href="https://cybersecurity.seas.wustl.edu/ning/index.html">Ning Zhang</a>,
                  <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
                  <br>
                  <em>USENIX Security</em>, 2019 
                  <br>
                  <a
                    href="https://arxiv.org/abs/1708.08327">arXiv</a>
                  /
                  <a href="https://github.com/shinington/Robust-PDF-Classifier-with-Conserved-Features">code</a>
                  /
                  <a href="https://www.youtube.com/watch?v=eOj7EipZmq0">video</a>
                  /
                  <a href="bibtex/tong2019improving.bib">bibtex</a>
                  <p></p>
                  <p>Is robust ML really robust in the face of real attacks on malware classifiers? If no, how to bridge the gap?</p>
                </td>
              </tr>              

              <!-- Multiple Learners -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/multiple_learner.png' width="160" height="160">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://proceedings.mlr.press/v80/tong18a/tong18a.pdf">
                    <papertitle>Adversarial Regression with Multiple Learners
                    </papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>*,
                  <a href="http://sixie-yu.org/">Sixie Yu*</a>,
                  <a href="https://salfeld.github.io/">Scott Alfeld</a>,
                  <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>
                  <br>
                  <em>ICML</em>, 2018 
                  <br>
                  <a href="http://proceedings.mlr.press/v80/tong18a/tong18a-supp.pdf">supplement</a>
                  /
                  <a href="https://arxiv.org/abs/1806.02256">arXiv</a>
                  /
                  <a href="https://github.com/marsplus/Adversarial-Regression-with-Multiple-Learners">code</a>
                  /
                  <a href="https://vimeo.com/287807252">video</a>
                  /
                  <a href="bibtex/tong2018adversarial.bib">bibtex</a>
                  <p></p>
                  <p>What if there are multiple ML models and a single adversary? What should be their optimal strategies?</p>
                </td>
              </tr>

              <!-- Traffic Scheduling -->
              <tr>
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <img src='images/traffic_scheduling.png' width="160" height="130">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="papers/tong2016application.pdf">
                    <papertitle>Application-Aware Traffic Scheduling for Workload Offloading in Mobile Clouds
                    </papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,
                  <a href="http://web.eecs.utk.edu/~weigao/">Wei Gao</a>
                  <br>
                  <em>INFOCOM</em>, 2016 &nbsp <font color="red"><strong>(Best Presentation in Session)</strong></font>
                  <br>
                  <a href="slides/tong2016application_slides.pdf">slides</a>
                  /
                  <a href="bibtex/tong2016application.bib">bibtex</a>
                  <p></p>
                  <p>How to adaptively balance the tradeoff between energy efficiency and responsiveness of mobile applications if they are offloaded to edge cloud?</p>
                </td>
              </tr>

              <!-- Hierarchical Edge Cloud -->
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/hierarchical.png' width="160" height="130">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="papers/tong2016a.pdf">
                    <papertitle>A Hierarchical Edge Cloud Architecture for Mobile Computing
                    </papertitle>
                  </a>
                  <br>
                  <strong><span style="font-size: 15px">Liang Tong</span></strong>,
                  Yong Li,
                  <a href="http://web.eecs.utk.edu/~weigao/">Wei Gao</a>
                  <br>
                  <em>INFOCOM</em>, 2016 &nbsp <font color="red"><strong>(The 2nd most cited paper at INFOCOM'16)</strong></font>
                  <br>
                  <a href="slides/tong2016a_slides.pdf">slides</a>
                  /
                  <a href="bibtex/tong2016a.bib">bibtex</a>
                  <p></p>
                  <p>The first work on hierarchical edge cloud architecture for mobile applications.</p>
                </td>
              </tr>              
              
            </tbody>
          </table>  

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Patents</heading>
                  <ul>
                    <li>
                    <a href="https://patents.google.com/patent/US20220067521A1/en">
                      <papertitle>Robust Enhancement for Face Recognition
                      </papertitle>
                    </a>
                    <br>
                    <a href="https://sites.google.com/site/zhengzhangchen/">Zhengzhang Chen</a>,
                    <a href="https://haifengchen.gitlab.io/intro/">Haifeng Chen</a>,
                    <strong><span style="font-size: 15px">Liang Tong</span></strong>
                    <br>
                    US Patent App. 17/464,148, 2022 (pending)
                    </li>
                  </ul>  
                  <ul>
                    <li>
                    <a href="https://patents.google.com/patent/US20220067432A1/en">
                      <papertitle>Robust Assessment for Face Recognition
                      </papertitle>
                    </a>
                    <br>
                    <a href="https://sites.google.com/site/zhengzhangchen/">Zhengzhang Chen</a>,
                    <a href="https://haifengchen.gitlab.io/intro/">Haifeng Chen</a>,
                    <strong><span style="font-size: 15px">Liang Tong</span></strong>
                    <br>
                    US Patent App. 17/464,127, 2022 (pending)
                    </li>
                  </ul>  
                  <ul>
                    <li>
                    <a href="https://patents.google.com/patent/US20210300433A1/en">
                      <papertitle>Systems and Methods for Defending against Physical Attacks on Image Classification
                      </papertitle>
                    </a>
                    <br>
                    <a href="https://vorobeychik.com/">Yevgeniy Vorobeychik</a>,
                    <a href="https://tongwu2020.github.io/tongwu/">Tong Wu</a>,
                    <strong><span style="font-size: 15px">Liang Tong</span></strong>
                    <br>
                    US Patent App. 17/214,071, 2021
                    </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>My Interns</heading>
                  <ul>
                    <li>Nauman Ahad (Georgia Tech): summer 2021</li>
                  </ul>
                  <ul>
                    <li><a href="http://web.eecs.utk.edu/~zli96/">Zhuohang Li</a> (UTK): summer 2022</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Teaching</heading>
                  <ul>
                    <li>CSE 411A AI and Society (Fall 2019), Washington University in St. Louis</li>
                    <li>CSE 544T Special Topics in Computer Science Theory - Adversarial AI (Spring 2019), Washington University in St. Louis </li>
                    <li>CS 102 Introduction to Computer Science (Spring 2015), University of Tennessee</li>
                    <li>CS 160 Computer Organization (Fall 2014), University of Tennessee</li>
                    <li>Access Network Technology (Spring 2011), University of Electronic Science and Technology of China</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="2">
                    Website credit: <a href="https://jonbarron.info/">Jon Barron</a>
                  </font>
                </p>
                <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=ZUZeTz8YcUit_b-qYu9Mrs8m7h9TxyejuMhXWS_6TDQ"></script>                
              </td>
            </tr>
          </table>

        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>
